{"cells":[{"cell_type":"markdown","metadata":{},"source":["**Import**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import zipfile\n","import os\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, Dataset, Subset, random_split\n","from PIL import Image\n","from sklearn.model_selection import KFold\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F\n","from skimage.metrics import structural_similarity as ssim\n","import cv2\n","from tqdm.auto import tqdm\n","from torchvision.models import resnet50, ResNet50_Weights\n","from torchvision.datasets import ImageFolder\n","from pathlib import Path\n","import numpy as np\n","from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay, f1_score\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!git clone https://github.com/Mvryo02/AnomalyDetection_PlaneBlade.git"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def bilateral_filter(image):\n","    np_image = np.array(image)  # Convert PIL image to numpy array\n","    filtered = cv2.bilateralFilter(np_image, d=9, sigmaColor=75, sigmaSpace=75)\n","    return Image.fromarray(filtered)  # Convert back to PIL image\n","\n","def sharpen(image):\n","    np_image = np.array(image)  # Convert PIL image to numpy array\n","    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n","    sharpened = cv2.filter2D(np_image, -1, kernel)\n","    return Image.fromarray(sharpened)  # Convert back to PIL image\n","\n","class CustomTransform:\n","    def __init__(self, additional_transform=None):\n","        self.additional_transform = additional_transform\n","\n","    def __call__(self, img):\n","        img = bilateral_filter(img) \n","        img = sharpen(img)  \n","        if self.additional_transform:\n","            img = self.additional_transform(img)\n","        return img\n","\n","transform_train = transforms.Compose([\n","    CustomTransform(),                      # Apply costum filters\n","    transforms.RandomHorizontalFlip(p=0.5), # random horizontal flip\n","    transforms.RandomRotation(15),          # random rotation of 15 degrees\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation = 0.2), \n","    transforms.Resize((224,224)),          \n","    transforms.ToTensor(),                # Convert image to tensor  \n","])\n","\n","transform_test = transforms.Compose([\n","    CustomTransform(),  \n","    transforms.Resize((224,224)),\n","    transforms.ToTensor(),\n","\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def decision_function(segm_map):  \n","\n","    mean_top_10_values = []\n","\n","    for map in segm_map:\n","        # Flatten the tensor\n","        flattened_tensor = map.reshape(-1)\n","\n","        # Sort the flattened tensor along the feature dimension (descending order)\n","        sorted_tensor, _ = torch.sort(flattened_tensor,descending=True)\n","\n","        # Take the top 10 values along the feature dimension\n","        mean_top_10_value = sorted_tensor[:10].mean()\n","\n","        mean_top_10_values.append(mean_top_10_value)\n","\n","    return torch.stack(mean_top_10_values)"]},{"cell_type":"markdown","metadata":{},"source":["**Method 1: Autoencoder**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#model 1 \n","class Autoencoder1(nn.Module):\n","    def __init__(self):\n","        super(Autoencoder1, self).__init__()\n","\n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),  \n","            nn.ReLU(True),        \n","            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1), \n","            nn.ReLU(True),\n","            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1), \n","            nn.ReLU(True)\n","        )\n","\n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),  \n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1), \n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=2, padding=1, output_padding=1),   \n","            nn.Sigmoid()   \n","        )\n","\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Model 2\n","class Autoencoder2(nn.Module):\n","    def __init__(self):\n","        super(Autoencoder2, self).__init__()\n","        \n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),  \n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  \n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),  \n","            nn.ReLU(),\n","            nn.Dropout(0.2)\n","        )\n","        \n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),  \n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  \n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.ConvTranspose2d(64, 1, kernel_size=3, stride=2, padding=1, output_padding=1),  \n","            nn.Sigmoid() \n","        )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Model 3\n","class Autoencoder3(nn.Module):\n","    def __init__(self):\n","        super(Autoencoder3, self).__init__()\n","        \n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),  \n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  \n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),  \n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),  \n","            nn.ReLU(),\n","            nn.Dropout(0.2)\n","        )\n","        \n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1), \n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),  \n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  \n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1),  \n","            nn.Sigmoid()  # Mappare i valori tra [0,1]\n","        )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x\n"]},{"cell_type":"markdown","metadata":{},"source":["**Method 1 : Autoencoder - Training**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_image_path = Path('/kaggle/working/AnomalyDetection_PlaneBlade-/train_detector')\n","\n","good_dataset = ImageFolder(root=train_image_path, transform=transform_train)\n","train_dataset, validation_dataset = torch.utils.data.random_split(good_dataset, [0.8, 0.2])\n","\n","# Set the batch size\n","BS = 32\n","\n","# Create data loaders for training and testing datasets\n","train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True)\n","validation_loader = DataLoader(validation_dataset, batch_size=BS, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = Autoencoder3()\n","model.cuda()\n","criterion = torch.nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr= 0.001)\n","Loss = []\n","Validation_Loss = []\n","\n","\n","def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=15):\n","    for epoch in range(epochs):\n","        model.train()  # Modalit√† di training\n","        train_loss = 0.0\n","        for images, _ in train_loader:\n","            images = images.to('cuda')\n","\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, images)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","        Loss.append(train)\n","        # Validation\n","        model.eval()\n","        val_loss = 0.0\n","        with torch.no_grad():\n","            for images, _ in val_loader:\n","                images = images.to('cuda')\n","                outputs = model(images)\n","                loss = criterion(outputs, images)\n","                val_loss += loss.item()\n","\n","        print(f\"Epoch {epoch+1}, Training Loss: {train_loss/len(train_loader)}, Validation Loss: {val_loss/len(val_loader)}\")\n","        Loss.append(train_loss)\n","        Validation_Loss.append(val_loss)\n","\n","\n","train_model(model, train_loader, val_loader, criterion, optimizer, epochs=15)\n","plt.plot(Loss, label='Training Loss')\n","plt.plot(Validation_Loss, label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.eval()\n","\n","RECON_ERROR=[]\n","for data,_ in train_loader:\n","    \n","    with torch.no_grad():\n","         recon = model(test_image.cuda())\n","    # Compute the loss\n","    recon_error =  ((features-recon)**2).mean(axis=(1))[:,3:-3,3:-3]\n","    # anomaly_score = segm_map.mean(axis=(1,2))\n","    \n","    RECON_ERROR.append(recon_error.cpu().unsqueeze(0))\n","    \n","RECON_ERROR = torch.cat(RECON_ERROR).cpu().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["possible_threshold = np.mean(RECON_ERROR) + 3 * np.std(RECON_ERROR)\n","\n","heat_map_max, heat_map_min = np.max(RECON_ERROR), np.min(RECON_ERROR)\n","\n","plt.hist(RECON_ERROR,bins=50)\n","plt.vlines(x=best_threshold,ymin=0,ymax=30,color='r')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["**Method 1 : Autoencoder - Testing**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y_true=[]\n","y_score=[]\n","\n","model.eval()\n","from pathlib import Path\n","\n","\n","\n","test_path = Path('/kaggle/working/AnomalyDetection_PlaneBlade/test_detector')\n","\n","for path in test_path.glob('*/*.png'):\n","    fault_type = path.parts[-2]\n","    test_image = transform_test(Image.open(path)).cuda().unsqueeze(0)\n","    \n","    with torch.no_grad():\n","        \n","        # Forward pass\n","        recon = model(test_image)\n","    \n","    y_score_image = ((test_image - recon)**2).mean(axis=(1)).mean()\n","\n","        \n","    y_true_image = 0 if fault_type == 'good' else 1\n","    \n","    y_true.append(y_true_image)\n","    y_score.append(y_score_image.cpu().numpy())\n","    \n","y_true = np.array(y_true)\n","y_score = np.array(y_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fpr, tpr, thresholds = roc_curve(y_true, y_score)\n","\n","\n","f1_scores = [f1_score(y_true, (y_score >= threshold).astype(int)) for threshold in thresholds]\n","\n","# Select the best threshold based on F1 score\n","best_threshold = thresholds[np.argmax(f1_scores)]\n","\n","#best_threshold=... to set the threshold to a wanted value\n","\n","print(f'best_threshold = {best_threshold}')\n","\n","auc_roc_score = roc_auc_score(y_true, (y_score >= best_threshold).astype(int))\n","\n","print(\"AUC-ROC Score:\", auc_roc_score)\n","precision = precision_score(y_true, (y_score >= best_threshold).astype(int))\n","recall = recall_score(y_true, (y_score >= best_threshold).astype(int))\n","\n","\n","print(f'Precision: {precision:.2f}')\n","print(f'Recall: {recall:.2f}')\n","\n","# Plot ROC curve\n","fpr, tpr, thresholds = roc_curve(y_true, y_score)\n","plt.figure()\n","plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc_roc_score)\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","\n","cm = confusion_matrix(y_true, (y_score >= best_threshold).astype(int))\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['OK','NOK'])\n","disp.plot()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["**Method 2: Autoencoder with a ResNet for feature extraction**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class resnet_feature_extractor(torch.nn.Module):\n","    def __init__(self):\n","        \"\"\"This class extracts the feature maps from a pretrained Resnet model.\"\"\"\n","        super(resnet_feature_extractor, self).__init__()\n","        self.model = resnet50(weights=ResNet50_Weights.DEFAULT)\n","\n","        self.model.eval()\n","        for param in self.model.parameters():\n","            param.requires_grad = False\n","\n","        \n","\n","        # Hook to extract feature maps\n","        def hook(module, input, output) -> None:\n","            \"\"\"This hook saves the extracted feature map on self.featured.\"\"\"\n","            self.features.append(output)\n","\n","        self.model.layer2[-1].register_forward_hook(hook)            \n","        self.model.layer3[-1].register_forward_hook(hook) \n","\n","    def forward(self, input):\n","\n","        self.features = []\n","        with torch.no_grad():\n","            _ = self.model(input)\n","\n","        self.avg = torch.nn.AvgPool2d(3, stride=1)\n","        fmap_size = self.features[0].shape[-2]         # Feature map sizes h, w\n","        self.resize = torch.nn.AdaptiveAvgPool2d(fmap_size)\n","\n","        resized_maps = [self.resize(self.avg(fmap)) for fmap in self.features]\n","        patch = torch.cat(resized_maps, 1)            # Merge the resized feature maps\n","\n","        return patch"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["resnet_model = resnet50(weights=ResNet50_Weights.DEFAULT)\n","backbone = resnet_feature_extractor()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Model 1\n","class AutoEncoder(nn.Module):\n","    def __init__(self):\n","        super(AutoEncoder, self).__init__()\n","    \n","       \n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(1536, 868, kernel_size=1, stride=1),\n","            nn.BatchNorm2d(868),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),  \n","            \n","            nn.Conv2d(868, 200, kernel_size=1, stride=1), \n","            nn.BatchNorm2d(200),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),  \n","            \n","            nn.Conv2d(200, 100, kernel_size=1, stride=1),  \n","        )\n","        \n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.Conv2d(100, 200, kernel_size=1, stride=1), \n","            nn.BatchNorm2d(200),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            \n","            nn.Conv2d(200, 868, kernel_size=1, stride=1),  \n","            nn.BatchNorm2d(868),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),  \n","            \n","            nn.Conv2d(868, 1536, kernel_size=1, stride=1),  \n","        )\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Model 2\n","class AutoEncoder2(nn.Module):\n","    def __init__(self):\n","        super(AutoEncoder, self).__init__()\n","    \n","       \n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(1536, 868, kernel_size=1, stride=1),\n","            nn.BatchNorm2d(868),\n","            nn.ReLU(),\n","            \n","            nn.Conv2d(868, 200, kernel_size=1, stride=1), \n","            nn.BatchNorm2d(200),\n","            nn.ReLU(), \n","            \n","            nn.Conv2d(200, 100, kernel_size=1, stride=1),  \n","        )\n","        \n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.Conv2d(100, 200, kernel_size=1, stride=1), \n","            nn.BatchNorm2d(200),\n","            nn.ReLU(),\n","            \n","            nn.Conv2d(200, 868, kernel_size=1, stride=1),  \n","            nn.BatchNorm2d(868),\n","            nn.ReLU(), \n","            \n","            nn.Conv2d(868, 1536, kernel_size=1, stride=1),  \n","        )\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Model 3\n","class AutoEncoder3(nn.Module):\n","    def __init__(self):\n","        super(AutoEncoder, self).__init__()\n","    \n","       \n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(1536, 868, kernel_size=1, stride=1),\n","            nn.BatchNorm2d(868),\n","            nn.ReLU(),\n","              \n","            \n","            nn.Conv2d(868, 400, kernel_size=1, stride=1), \n","            nn.BatchNorm2d(400),\n","            nn.ReLU(),\n","\n","            nn.Conv2d(400, 200, kernel_size=1, stride=1), \n","            nn.BatchNorm2d(200),\n","            nn.ReLU(),\n","             \n","            \n","            nn.Conv2d(200, 100, kernel_size=1, stride=1),  \n","        )\n","        \n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.Conv2d(100, 200, kernel_size=1, stride=1), \n","            nn.BatchNorm2d(200),\n","            nn.ReLU(),\n","            \n","            nn.Conv2d(200, 400, kernel_size=1, stride=1),  \n","            nn.BatchNorm2d(400),\n","            nn.ReLU(),\n","\n","            nn.Conv2d(400, 868, kernel_size=1, stride=1),  \n","            nn.BatchNorm2d(868),\n","            nn.ReLU(),\n","        \n","            \n","            nn.Conv2d(868, 1536, kernel_size=1, stride=1),  \n","        )\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["**Method 2: Autoencoder with a ResNet for feature extraction - Training**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = AutoEncoder(in_channels=1536, latent_dim=100).cuda()\n","backbone.cuda()\n","model.cuda()\n","# Define loss function and optimizer\n","criterion = torch.nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Loss = []  \n","Validation_Loss = []  \n","num_epochs = 15\n","for epoch in tqdm(range(num_epochs)):\n","    model.train()\n","    for data,_ in train_loader:\n","        with torch.no_grad():\n","            features = backbone(data.cuda())\n","        # Forward pass\n","        output = model(features)\n","        # Compute the loss\n","        loss = criterion(output, features)\n","        # Backpropagation and optimization step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    \n","    \n","    Loss.append(loss.item())\n","\n","    \n","    model.eval()  \n","    with torch.no_grad():\n","        val_loss_sum = 0.0\n","        num_batches = 0\n","        for data, _ in validation_loader:\n","            features = backbone(data.cuda())\n","            output = model(features)\n","            val_loss = criterion(output, features)\n","            val_loss_sum += val_loss.item()\n","            num_batches += 1\n","        val_loss_avg = val_loss_sum / num_batches\n","        Validation_Loss.append(val_loss_avg)\n","\n","    \n","    \n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Validation Loss: {val_loss_avg:.4f}')\n","\n","\n","plt.plot(Loss, label='Training Loss')\n","plt.plot(Validation_Loss, label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.eval()\n","\n","RECON_ERROR=[]\n","for data,_ in train_loader:\n","    \n","    with torch.no_grad():\n","        features = backbone(data.cuda()).squeeze()\n","        # Forward pass\n","        recon = model(features)\n","    # Compute the loss\n","    segm_map =  ((features-recon)**2).mean(axis=(1))[:,3:-3,3:-3]\n","    anomaly_score = decision_function(segm_map)\n","    # anomaly_score = segm_map.mean(axis=(1,2))\n","    \n","    RECON_ERROR.append(anomaly_score)\n","    \n","RECON_ERROR = torch.cat(RECON_ERROR).cpu().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["possible_threshold = np.mean(RECON_ERROR) + 3 * np.std(RECON_ERROR)\n","\n","heat_map_max, heat_map_min = np.max(RECON_ERROR), np.min(RECON_ERROR)\n","\n","plt.hist(RECON_ERROR,bins=50)\n","plt.vlines(x=best_threshold,ymin=0,ymax=30,color='r')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["**Method 2: Autoencoder with a ResNet for feature extraction - Testing**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y_true=[]\n","y_score=[]\n","\n","model.eval()\n","backbone.eval()\n","\n","\n","test_path = Path('/kaggle/working/AnomalyDetection_PlaneBlade/test_detector')\n","\n","for path in test_path.glob('*/*.png'):\n","    fault_type = path.parts[-2]\n","    test_image = transform_test(Image.open(path)).cuda().unsqueeze(0)\n","    \n","    with torch.no_grad():\n","        features = backbone(test_image)\n","        # Forward pass\n","        recon = model(features)\n","    \n","    segm_map = ((features - recon)**2).mean(axis=(1))[:,8:-8,8:-8]\n","    y_score_image = decision_function(segm_map=segm_map)\n","    \n","    y_true_image = 0 if fault_type == 'good' else 1\n","    \n","    y_true.append(y_true_image)\n","    y_score.append(y_score_image.cpu().numpy())\n","    \n","y_true = np.array(y_true)\n","y_score = np.array(y_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fpr, tpr, thresholds = roc_curve(y_true, y_score)\n","\n","# Calcolo dei F1 scores per ogni threshold\n","f1_scores = [f1_score(y_true, (y_score >= threshold).astype(int)) for threshold in thresholds]\n","\n","# Select the best threshold based on F1 score\n","best_threshold = thresholds[np.argmax(f1_scores)]\n","\n","#best_threshold=...\n","\n","print(f'best_threshold = {best_threshold}')\n","\n","auc_roc_score = roc_auc_score(y_true, (y_score >= best_threshold).astype(int))\n","\n","print(\"AUC-ROC Score:\", auc_roc_score)\n","\n","# Plot ROC curve\n","fpr, tpr, thresholds = roc_curve(y_true, y_score)\n","plt.figure()\n","plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc_roc_score)\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","\n","cm = confusion_matrix(y_true, (y_score >= best_threshold).astype(int))\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['OK','NOK'])\n","disp.plot()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["**Classifier: Models**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#CLassifier 1\n","class Classifier1(nn.Module):\n","    def __init__(self, num_classes):\n","        super(Classifier1, self).__init__()\n","        self.conv_layers = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        self.fc_layers = nn.Sequential(\n","            nn.Linear(64 * 26 * 26, 128),  \n","            nn.ReLU(),\n","            nn.Linear(128, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.conv_layers(x)  \n","        x = torch.flatten(x, 1) \n","        x = self.fc_layers(x)  \n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#CLassifier 2\n","class Classifier2(nn.Module):\n","    def __init__(self, num_classes):\n","        super(Classifier2, self).__init__()\n","        self.conv_layers = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        self.fc_layers = nn.Sequential(\n","            nn.Linear(64 * 26 * 26, 128),  \n","            nn.ReLU(),\n","            nn.Dropout(p=0.5),\n","            nn.Linear(128, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.conv_layers(x)  \n","        x = torch.flatten(x, 1)  \n","        x = self.fc_layers(x) \n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Classifier 3\n","class Classifier3(nn.Module):\n","    def __init__(self, num_classes):\n","        super(Classifier3, self).__init__()\n","        self.conv_layers = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        self.fc_layers = nn.Sequential(\n","            nn.Linear(64 * 26 * 26, 128),  \n","            nn.ReLU(),\n","            nn.Dropout(p=0.5),\n","            nn.Linear(128, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.conv_layers(x)  \n","        x = torch.flatten(x, 1)  \n","        x = self.fc_layers(x) \n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["**Classifier: Training**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["num_classes = 4  #ablation, groove, facture, breakdown\n","\n","\n","classifier  = Classifier3(num_classes).cuda()\n","classifier.eval()\n","\n","criterion = nn.CrossEntropyLoss().cuda()\n","optimizer = optim.Adam(classifier.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train2_image_path = Path('/kaggle/working/AnomalyDetection_PlaneBlade/train_classifier')\n","\n","dataset = ImageFolder(root=train2_image_path, transform=transform)\n","train2_dataset, validation_dataset = torch.utils.data.random_split(dataset, [0.8, 0.2])\n","# Set the batch size\n","BS = 32\n","\n","# Create data loaders for training and testing datasets\n","classifier_train_loader = DataLoader(train2_dataset, batch_size=BS, shuffle=True)\n","classifier_validation_loader = DataLoader(validation_dataset, batch_size=BS, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train_and_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n","    for epoch in range(num_epochs):\n","        model.train() \n","        for images, labels in train_loader:\n","            images, labels = images.cuda(), labels.cuda() \n","            optimizer.zero_grad()  \n","            outputs = model(images)  \n","            loss = criterion(outputs, labels)  \n","            loss.backward()  \n","            optimizer.step()  \n","\n","        # Validazione\n","        model.eval()  \n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for images, labels in val_loader:\n","                images, labels = images.cuda(), labels.cuda()  \n","                outputs = model(images)  \n","                _, predicted = torch.max(outputs.data, 1) \n","                total += labels.size(0) \n","                correct += (predicted == labels).sum().item()  \n","\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Accuracy: {100 * correct / total:.2f}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["num_epochs = 25\n","train_and_validate(classifier, classifier_train_loader, classifier_validation_loader, criterion, optimizer, num_epochs)"]},{"cell_type":"markdown","metadata":{},"source":["**Classifier: Testing**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_image_path = Path('/kaggle/working/AnomalyDetection_PlaneBlade/test_classifier')\n","testset=ImageFolder(root=train2_image_path, transform=transform)\n","classifier_test_loader = DataLoader(testset, batch_size=BS, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def test_model(model, test_loader):\n","    model.eval()  # Imposta il modello in modalit√† valutazione (disattiva dropout, batchnorm, ecc.)\n","    correct = 0\n","    total = 0\n","    all_predictions = []\n","    all_labels = []\n","    \n","    with torch.no_grad():  # Disattiva il calcolo del gradiente\n","        for images, labels in test_loader:\n","            images, labels = images.cuda(), labels.cuda()  # Sposta su GPU se disponibile\n","            outputs = model(images)  # Passa le immagini attraverso il modello\n","            _, predicted = torch.max(outputs.data, 1)  # Ottieni le predizioni con il massimo logit\n","            total += labels.size(0)  # Incrementa il numero totale di campioni\n","            correct += (predicted == labels).sum().item()  # Conta le predizioni corrette\n","            all_predictions.extend(predicted.cpu().numpy())  # Salva le predizioni\n","            all_labels.extend(labels.cpu().numpy())  # Salva le etichette reali\n","\n","    accuracy = 100 * correct / total  # Calcola l'accuratezza\n","    print(f'Test Accuracy: {accuracy:.2f}%')\n","\n","    return all_predictions, all_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["predictions, labels = test_model(classifier, classifier_test_loader)\n","from sklearn.metrics import classification_report, confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Classification Report\n","print(classification_report(labels, predictions))\n","\n","\n","conf_matrix = confusion_matrix(labels, predictions)\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n","plt.ylabel('True Label')\n","plt.xlabel('Predicted Label')\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
