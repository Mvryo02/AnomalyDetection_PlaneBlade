{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Import**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport zipfile\nimport os\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, Dataset, Subset, random_split\nfrom PIL import Image\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom skimage.metrics import structural_similarity as ssim\nimport cv2\nfrom tqdm.auto import tqdm\nfrom torchvision.models import resnet50, ResNet50_Weights\nfrom torchvision.datasets import ImageFolder\nfrom pathlib import Path\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay, f1_score\nimport seaborn as sns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/Mvryo02/AnomalyDetection_PlaneBlade.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def bilateral_filter(image):\n    np_image = np.array(image)  # Convert PIL image to numpy array\n    filtered = cv2.bilateralFilter(np_image, d=9, sigmaColor=75, sigmaSpace=75)\n    return Image.fromarray(filtered)  # Convert back to PIL image\n\ndef sharpen(image):\n    np_image = np.array(image)  # Convert PIL image to numpy array\n    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n    sharpened = cv2.filter2D(np_image, -1, kernel)\n    return Image.fromarray(sharpened)  # Convert back to PIL image\n\nclass CustomTransform:\n    def __init__(self, additional_transform=None):\n        self.additional_transform = additional_transform\n\n    def __call__(self, img):\n        img = bilateral_filter(img) \n        img = sharpen(img)  \n        if self.additional_transform:\n            img = self.additional_transform(img)\n        return img\n\ntransform_train = transforms.Compose([\n    CustomTransform(),                     # Apply costum filters\n    transforms.Resize((224,224)),          \n    transforms.ToTensor(),                # Convert image to tensor\n])\n\ntransform_test = transforms.Compose([\n    CustomTransform(),  \n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Method 1: Autoencoder**","metadata":{}},{"cell_type":"code","source":"#model 1 \nclass Autoencoder1(nn.Module):\n    def __init__(self):\n        super(ConvAutoencoder, self).__init__()\n\n        # Encoder\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),  \n            nn.ReLU(True),        \n            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1), \n            nn.ReLU(True),\n            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1), \n            nn.ReLU(True)\n        )\n\n        # Decoder\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),  \n            nn.ReLU(True),\n            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1), \n            nn.ReLU(True),\n            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=2, padding=1, output_padding=1),   \n            nn.Sigmoid()   \n        )\n\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Model 2\nclass Autoencoder2(nn.Module):\n    def __init__(self):\n        super(Autoencoder, self).__init__()\n        \n        # Encoder\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),  \n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  \n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),  \n            nn.ReLU(),\n            nn.Dropout(0.2)\n        )\n        \n        # Decoder\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),  \n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  \n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.ConvTranspose2d(64, 1, kernel_size=3, stride=2, padding=1, output_padding=1),  \n            nn.Sigmoid() \n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Model 3\nclass Autoencoder3(nn.Module):\n    def __init__(self):\n        super(Autoencoder3, self).__init__()\n        \n        # Encoder\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),  \n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  \n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),  \n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),  \n            nn.ReLU(),\n            nn.Dropout(0.2)\n        )\n        \n        # Decoder\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1), \n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),  \n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  \n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1),  \n            nn.Sigmoid()  # Mappare i valori tra [0,1]\n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Method 1 : Autoencoder - Training**","metadata":{}},{"cell_type":"code","source":"train_image_path = Path('/kaggle/working/AnomalyDetection_PlaneBlade-/train_detector')\n\ngood_dataset = ImageFolder(root=train_image_path, transform=transform_train)\ntrain_dataset, validation_dataset = torch.utils.data.random_split(good_dataset, [0.8, 0.2])\n\n# Set the batch size\nBS = 32\n\n# Create data loaders for training and testing datasets\ntrain_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True)\nvalidation_loader = DataLoader(validation_dataset, batch_size=BS, shuffle=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = Autoencoder3()\nmodel.cuda()\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr= 0.001)\nLoss = []\nValidation_Loss = []\n\n\ndef train_model(model, train_loader, val_loader, criterion, optimizer, epochs=15):\n    for epoch in range(epochs):\n        model.train()  # Modalità di training\n        train_loss = 0.0\n        for images, _ in train_loader:\n            images = images.to('cuda')\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, images)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n        Loss.append(train)\n        # Validation\n        model.eval()\n        val_loss = 0.0\n        with torch.no_grad():\n            for images, _ in val_loader:\n                images = images.to('cuda')\n                outputs = model(images)\n                loss = criterion(outputs, images)\n                val_loss += loss.item()\n\n        print(f\"Epoch {epoch+1}, Training Loss: {train_loss/len(train_loader)}, Validation Loss: {val_loss/len(val_loader)}\")\n        Loss.append(train_loss)\n        Validation_Loss.append(val_loss)\n\n\ntrain_model(model, train_loader, val_loader, criterion, optimizer, epochs=15)\nplt.plot(Loss, label='Training Loss')\nplt.plot(Validation_Loss, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\n\nRECON_ERROR=[]\nfor data,_ in train_loader:\n    \n    with torch.no_grad():\n         recon = model(test_image.cuda())\n    # Compute the loss\n    segm_map =  ((features-recon)**2).mean(axis=(1))[:,3:-3,3:-3]\n    anomaly_score = decision_function(segm_map)\n    # anomaly_score = segm_map.mean(axis=(1,2))\n    \n    RECON_ERROR.append(anomaly_score)\n    \nRECON_ERROR = torch.cat(RECON_ERROR).cpu().numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"possible_threshold = np.mean(RECON_ERROR) + 3 * np.std(RECON_ERROR)\n\nheat_map_max, heat_map_min = np.max(RECON_ERROR), np.min(RECON_ERROR)\n\nplt.hist(RECON_ERROR,bins=50)\nplt.vlines(x=best_threshold,ymin=0,ymax=30,color='r')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Method 1 : Autoencoder - Testing**","metadata":{}},{"cell_type":"code","source":"def decision_function(segm_map):  \n\n    mean_top_10_values = []\n\n    for map in segm_map:\n        # Flatten the tensor\n        flattened_tensor = map.reshape(-1)\n\n        # Sort the flattened tensor along the feature dimension (descending order)\n        sorted_tensor, _ = torch.sort(flattened_tensor,descending=True)\n\n        # Take the top 10 values along the feature dimension\n        mean_top_10_value = sorted_tensor[:10].mean()\n\n        mean_top_10_values.append(mean_top_10_value)\n\n    return torch.stack(mean_top_10_values)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true=[]\ny_score=[]\n\nmodel.eval()\nfrom pathlib import Path\n\n\n\ntest_path = Path('/kaggle/working/AnomalyDetection_PlaneBlade/test_detector')\n\nfor path in test_path.glob('*/*.png'):\n    fault_type = path.parts[-2]\n    test_image = transform_test(Image.open(path)).cuda().unsqueeze(0)\n    \n    with torch.no_grad():\n        \n        # Forward pass\n        recon = model(test_image)\n    \n    segm_map = ((test_image - recon)**2).mean(axis=(1))[:,8:-8,8:-8]\n    y_score_image = decision_function(segm_map=segm_map)\n    # y_score_image = segm_map.mean(axis=(1,2))\n    \n    \n    y_true_image = 0 if fault_type == 'good' else 1\n    \n    y_true.append(y_true_image)\n    y_score.append(y_score_image.cpu().numpy())\n    \ny_true = np.array(y_true)\ny_score = np.array(y_score)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fpr, tpr, thresholds = roc_curve(y_true, y_score)\n\n\nf1_scores = [f1_score(y_true, (y_score >= threshold).astype(int)) for threshold in thresholds]\n\n# Select the best threshold based on F1 score\nbest_threshold = thresholds[np.argmax(f1_scores)]\n\n#best_threshold=... to set the threshold to a wanted value\n\nprint(f'best_threshold = {best_threshold}')\n\nauc_roc_score = roc_auc_score(y_true, (y_score >= best_threshold).astype(int))\n\nprint(\"AUC-ROC Score:\", auc_roc_score)\nprecision = precision_score(y_true, (y_score >= best_threshold).astype(int))\nrecall = recall_score(y_true, (y_score >= best_threshold).astype(int))\n\n\nprint(f'Precision: {precision:.2f}')\nprint(f'Recall: {recall:.2f}')\n\n# Plot ROC curve\nfpr, tpr, thresholds = roc_curve(y_true, y_score)\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc_roc_score)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\ncm = confusion_matrix(y_true, (y_score >= best_threshold).astype(int))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['OK','NOK'])\ndisp.plot()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Method 2: Autoencoder with a ResNet for feature extraction**","metadata":{}},{"cell_type":"code","source":"class resnet_feature_extractor(torch.nn.Module):\n    def __init__(self):\n        \"\"\"This class extracts the feature maps from a pretrained Resnet model.\"\"\"\n        super(resnet_feature_extractor, self).__init__()\n        self.model = resnet50(weights=ResNet50_Weights.DEFAULT)\n\n        self.model.eval()\n        for param in self.model.parameters():\n            param.requires_grad = False\n\n        \n\n        # Hook to extract feature maps\n        def hook(module, input, output) -> None:\n            \"\"\"This hook saves the extracted feature map on self.featured.\"\"\"\n            self.features.append(output)\n\n        self.model.layer2[-1].register_forward_hook(hook)            \n        self.model.layer3[-1].register_forward_hook(hook) \n\n    def forward(self, input):\n\n        self.features = []\n        with torch.no_grad():\n            _ = self.model(input)\n\n        self.avg = torch.nn.AvgPool2d(3, stride=1)\n        fmap_size = self.features[0].shape[-2]         # Feature map sizes h, w\n        self.resize = torch.nn.AdaptiveAvgPool2d(fmap_size)\n\n        resized_maps = [self.resize(self.avg(fmap)) for fmap in self.features]\n        patch = torch.cat(resized_maps, 1)            # Merge the resized feature maps\n\n        return patch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"resnet_model = resnet50(weights=ResNet50_Weights.DEFAULT)\nbackbone = resnet_feature_extractor()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Model 1\nAutoEncoder(nn.Module):\n    def __init__(self, in_channels=1000, latent_dim=50, is_bn=True):\n        super(AutoEncoder, self).__init__()\n    \n       \n        self.encoder = nn.Sequential(\n            nn.Conv2d(1536, 868, kernel_size=1, stride=1),\n            nn.BatchNorm2d(868),\n            nn.ReLU(),\n            nn.Dropout(0.3),  \n            \n            nn.Conv2d(868, 200, kernel_size=1, stride=1), \n            nn.BatchNorm2d(200),\n            nn.ReLU(),\n            nn.Dropout(0.3),  \n            \n            nn.Conv2d(200, 100, kernel_size=1, stride=1),  \n        )\n        \n        # Decoder\n        self.decoder = nn.Sequential(\n            nn.Conv2d(100, 200, kernel_size=1, stride=1), \n            nn.BatchNorm2d(200),\n            nn.ReLU(),\n            \n            nn.Conv2d(200, 868, kernel_size=1, stride=1),  \n            nn.BatchNorm2d(868),\n            nn.ReLU(),\n            nn.Dropout(0.3),  \n            \n            nn.Conv2d(868, 1536, kernel_size=1, stride=1),  \n    \n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Method 2: Autoencoder with a ResNet for feature extraction - Training**","metadata":{}},{"cell_type":"code","source":"model = AutoEncoder(in_channels=1536, latent_dim=100).cuda()\nbackbone.cuda()\nmodel.cuda()\n# Define loss function and optimizer\ncriterion = torch.nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.01)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Loss = []  \nValidation_Loss = []  ì\nnum_epochs = 15\nfor epoch in tqdm(range(num_epochs)):\n    model.train()\n    for data,_ in train_loader:\n        with torch.no_grad():\n            features = backbone(data.cuda())\n        # Forward pass\n        output = model(features)\n        # Compute the loss\n        loss = criterion(output, features)\n        # Backpropagation and optimization step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    \n    Loss.append(loss.item())\n\n    \n    model.eval()  \n    with torch.no_grad():\n        val_loss_sum = 0.0\n        num_batches = 0\n        for data, _ in validation_loader:\n            features = backbone(data.cuda())\n            output = model(features)\n            val_loss = criterion(output, features)\n            val_loss_sum += val_loss.item()\n            num_batches += 1\n        val_loss_avg = val_loss_sum / num_batches\n        Validation_Loss.append(val_loss_avg)\n\n    \n    \n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Validation Loss: {val_loss_avg:.4f}')\n\n\nplt.plot(Loss, label='Training Loss')\nplt.plot(Validation_Loss, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n# plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\n\nRECON_ERROR=[]\nfor data,_ in train_loader:\n    \n    with torch.no_grad():\n        features = backbone(data.cuda()).squeeze()\n        # Forward pass\n        recon = model(features)\n    # Compute the loss\n    segm_map =  ((features-recon)**2).mean(axis=(1))[:,3:-3,3:-3]\n    anomaly_score = decision_function(segm_map)\n    # anomaly_score = segm_map.mean(axis=(1,2))\n    \n    RECON_ERROR.append(anomaly_score)\n    \nRECON_ERROR = torch.cat(RECON_ERROR).cpu().numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"possible_threshold = np.mean(RECON_ERROR) + 3 * np.std(RECON_ERROR)\n\nheat_map_max, heat_map_min = np.max(RECON_ERROR), np.min(RECON_ERROR)\n\nplt.hist(RECON_ERROR,bins=50)\nplt.vlines(x=best_threshold,ymin=0,ymax=30,color='r')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Method 2: Autoencoder with a ResNet for feature extraction - Testing**","metadata":{}},{"cell_type":"code","source":"y_true=[]\ny_score=[]\n\nmodel.eval()\nbackbone.eval()\n\n\ntest_path = Path('/kaggle/working/AnomalyDetection_PlaneBlade/test_detector')\n\nfor path in test_path.glob('*/*.png'):\n    fault_type = path.parts[-2]\n    test_image = transform_test(Image.open(path)).cuda().unsqueeze(0)\n    \n    with torch.no_grad():\n        features = backbone(test_image)\n        # Forward pass\n        recon = model(features)\n    \n    segm_map = ((features - recon)**2).mean(axis=(1))[:,8:-8,8:-8]\n    y_score_image = decision_function(segm_map=segm_map)\n    \n    y_true_image = 0 if fault_type == 'good' else 1\n    \n    y_true.append(y_true_image)\n    y_score.append(y_score_image.cpu().numpy())\n    \ny_true = np.array(y_true)\ny_score = np.array(y_score)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fpr, tpr, thresholds = roc_curve(y_true, y_score)\n\n# Calcolo dei F1 scores per ogni threshold\nf1_scores = [f1_score(y_true, (y_score >= threshold).astype(int)) for threshold in thresholds]\n\n# Select the best threshold based on F1 score\nbest_threshold = thresholds[np.argmax(f1_scores)]\n\n#best_threshold=...\n\nprint(f'best_threshold = {best_threshold}')\n\nauc_roc_score = roc_auc_score(y_true, (y_score >= best_threshold).astype(int))\n\nprint(\"AUC-ROC Score:\", auc_roc_score)\n\n# Plot ROC curve\nfpr, tpr, thresholds = roc_curve(y_true, y_score)\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc_roc_score)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\ncm = confusion_matrix(y_true, (y_score >= best_threshold).astype(int))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['OK','NOK'])\ndisp.plot()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Classifier: Models**","metadata":{}},{"cell_type":"code","source":"#CLassifier 1\nclass Classifier1(nn.Module):\n    def __init__(self, num_classes):\n        super(Classifier1, self).__init__()\n        self.conv_layers = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n\n        self.fc_layers = nn.Sequential(\n            nn.Linear(64 * 26 * 26, 128),  # Assumendo un'entrata di 224x224\n            nn.ReLU(),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.conv_layers(x)  # Passa attraverso i layer convoluzionali\n        x = torch.flatten(x, 1)  # Appiattisci prima di passare ai fully connected\n        x = self.fc_layers(x)  # Passa attraverso i layer fully connected\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#CLassifier 2\nclass Classifier2(nn.Module):\n    def __init__(self, num_classes):\n        super(Classifier2, self).__init__()\n        self.conv_layers = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n\n        self.fc_layers = nn.Sequential(\n            nn.Linear(64 * 26 * 26, 128),  # Assumendo un'entrata di 224x224\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.conv_layers(x)  # Passa attraverso i layer convoluzionali\n        x = torch.flatten(x, 1)  # Appiattisci prima di passare ai fully connected\n        x = self.fc_layers(x)  # Passa attraverso i layer fully connected\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Classifier 3\nclass Classifier3(nn.Module):\n    def __init__(self, num_classes):\n        super(Classifier3, self).__init__()\n        self.conv_layers = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n\n        self.fc_layers = nn.Sequential(\n            nn.Linear(64 * 26 * 26, 128),  # Assumendo un'entrata di 224x224\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.conv_layers(x)  # Passa attraverso i layer convoluzionali\n        x = torch.flatten(x, 1)  # Appiattisci prima di passare ai fully connected\n        x = self.fc_layers(x)  # Passa attraverso i layer fully connected\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Classifier: Training**","metadata":{}},{"cell_type":"code","source":"num_classes = 4  #ablation, groove, facture, breakdown\n\n\nclassifier  = Classifier3(num_classes).cuda()\nclassifier.eval()\n\ncriterion = nn.CrossEntropyLoss().cuda()\noptimizer = optim.Adam(classifier.parameters(), lr=0.001)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train2_image_path = Path('/kaggle/working/AnomalyDetection_PlaneBlade/train_classifier')\n\ndataset = ImageFolder(root=train2_image_path, transform=transform)\ntrain2_dataset, validation_dataset = torch.utils.data.random_split(dataset, [0.8, 0.2])\n# Set the batch size\nBS = 32\n\n# Create data loaders for training and testing datasets\nclassifier_train_loader = DataLoader(train2_dataset, batch_size=BS, shuffle=True)\nclassifier_validation_loader = DataLoader(validation_dataset, batch_size=BS, shuffle=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_and_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n    for epoch in range(num_epochs):\n        model.train() \n        for images, labels in train_loader:\n            images, labels = images.cuda(), labels.cuda() \n            optimizer.zero_grad()  \n            outputs = model(images)  \n            loss = criterion(outputs, labels)  \n            loss.backward()  \n            optimizer.step()  \n\n        # Validazione\n        model.eval()  \n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.cuda(), labels.cuda()  \n                outputs = model(images)  \n                _, predicted = torch.max(outputs.data, 1) \n                total += labels.size(0) \n                correct += (predicted == labels).sum().item()  \n\n        print(f'Epoch [{epoch+1}/{num_epochs}], Accuracy: {100 * correct / total:.2f}%')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_epochs = 25\ntrain_and_validate(classifier, classifier_train_loader, classifier_validation_loader, criterion, optimizer, num_epochs)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Classifier: Testing**","metadata":{}},{"cell_type":"code","source":"test_image_path = Path('/kaggle/working/AnomalyDetection_PlaneBlade/test_classifier')\ntestset=ImageFolder(root=train2_image_path, transform=transform)\nclassifier_test_loader = DataLoader(testset, batch_size=BS, shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test_model(model, test_loader):\n    model.eval()  # Imposta il modello in modalità valutazione (disattiva dropout, batchnorm, ecc.)\n    correct = 0\n    total = 0\n    all_predictions = []\n    all_labels = []\n    \n    with torch.no_grad():  # Disattiva il calcolo del gradiente\n        for images, labels in test_loader:\n            images, labels = images.cuda(), labels.cuda()  # Sposta su GPU se disponibile\n            outputs = model(images)  # Passa le immagini attraverso il modello\n            _, predicted = torch.max(outputs.data, 1)  # Ottieni le predizioni con il massimo logit\n            total += labels.size(0)  # Incrementa il numero totale di campioni\n            correct += (predicted == labels).sum().item()  # Conta le predizioni corrette\n            all_predictions.extend(predicted.cpu().numpy())  # Salva le predizioni\n            all_labels.extend(labels.cpu().numpy())  # Salva le etichette reali\n\n    accuracy = 100 * correct / total  # Calcola l'accuratezza\n    print(f'Test Accuracy: {accuracy:.2f}%')\n\n    return all_predictions, all_labels","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions, labels = test_model(classifier, classifier_test_loader)\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Classification Report\nprint(classification_report(labels, predictions))\n\n\nconf_matrix = confusion_matrix(labels, predictions)\nplt.figure(figsize=(10, 8))\nsns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}